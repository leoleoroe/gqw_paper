{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/code/causal-learning/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-03 09:24:22,347 - /home/ubuntu/code/causal-learning/.venv/lib/python3.10/site-packages/castle/backend/__init__.py[line:36] - INFO: You can use `os.environ['CASTLE_BACKEND'] = backend` to set the backend(`pytorch` or `mindspore`).\n",
      "2024-07-03 09:24:22,408 - /home/ubuntu/code/causal-learning/.venv/lib/python3.10/site-packages/castle/algorithms/__init__.py[line:36] - INFO: You are using ``pytorch`` as the backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import Index, RangeIndex\n",
    "import numpy as np\n",
    "import math\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "from collections.abc import Iterable\n",
    "\n",
    "\n",
    "from causalAssembly.models_dag import ProductionLineGraph\n",
    "from causalAssembly.drf_fitting import fit_drf\n",
    "\n",
    "from castle.common import GraphDAG\n",
    "from castle.metrics import MetricsDAG\n",
    "from castle.datasets import IIDSimulation, DAG\n",
    "from castle.algorithms import Notears\n",
    "# adjust GAE algorithm\n",
    "# from castle.algorithms import GAE\n",
    "from castle.algorithms import DirectLiNGAM\n",
    "from castle.algorithms import PC\n",
    "\n",
    "from dagma.linear import DagmaLinear\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FREQUENCY = 100\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Referred from:\n",
    "    - https://stackoverflow.com/questions/38469632/tensorflow-non-repeatable-results\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    try:\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def compute_h(w_adj):\n",
    "\n",
    "    d = w_adj.shape[0]\n",
    "    h = torch.trace(torch.matrix_exp(w_adj * w_adj)) - d\n",
    "\n",
    "    return h\n",
    "\n",
    "\n",
    "class Tensor(np.ndarray):\n",
    "    \"\"\"A subclass of numpy.ndarray.\n",
    "\n",
    "    This subclass has all attributes and methods of numpy.ndarray\n",
    "    with two additional, user-defined attributes: `index` and `columns`.\n",
    "\n",
    "    It can be used in the same way as a standard numpy.ndarray.\n",
    "    However, after performing any operations on the Tensor (e.g., slicing,\n",
    "    transposing, arithmetic, etc.), the user-defined attribute values of\n",
    "    `index` and `columns` will be lost and replaced with a numeric indices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    object: array-like\n",
    "        Multiple list, ndarray, DataFrame\n",
    "    index : Index or array-like\n",
    "        Index to use for resulting tensor. Will default to RangeIndex if\n",
    "        no indexing information part of input data and no index provided.\n",
    "    columns : Index or array-like\n",
    "        Column labels to use for resulting tensor. Will default to\n",
    "        RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Create a Tensor from a list or numpy.ndarray.\n",
    "\n",
    "    >>> x = [[0, 3, 8, 1],\n",
    "    ...      [8, 4, 1, 9],\n",
    "    ...      [7, 3, 3, 7]]\n",
    "\n",
    "    Or\n",
    "\n",
    "    >>> x = np.random.randint(0, 10, size=12).reshape((3, 4))\n",
    "    >>> arr = Tensor(x)\n",
    "    >>> arr\n",
    "    Tensor([[0, 3, 8, 1],\n",
    "            [8, 4, 1, 9],\n",
    "            [7, 3, 3, 7]])\n",
    "    >>> arr.index\n",
    "    RangeIndex(start=0, stop=3, step=1)\n",
    "    >>> list(arr.index)\n",
    "    [0, 1, 2]\n",
    "    >>> arr.columns\n",
    "    RangeIndex(start=0, stop=4, step=1)\n",
    "    >>> list(arr.columns)\n",
    "    [0, 1, 2, 3]\n",
    "\n",
    "    `index` and `columns` can be set using kwargs.\n",
    "\n",
    "    >>> arr = Tensor(x, index=list('XYZ'), columns=list('ABCD'))\n",
    "    >>> arr\n",
    "    Tensor([[6, 1, 8, 9],\n",
    "            [1, 5, 2, 1],\n",
    "            [5, 9, 4, 5]])\n",
    "    >>> arr.index\n",
    "    Index(['x', 'y', 'z'], dtype='object')\n",
    "    >>> arr.columns\n",
    "    Index(['a', 'b', 'c', 'd'], dtype='object')\n",
    "\n",
    "    Or a value can be assigned to `arr.index` or `arr.columns`,\n",
    "    but it must be an `Iterable`.\n",
    "\n",
    "    >>> arr.index = list('xyz')\n",
    "    >>> arr.index\n",
    "    Index(['x', 'y', 'z'], dtype='object')\n",
    "    >>> arr.columns = list('abcd')\n",
    "    >>> arr.columns\n",
    "    Index(['a', 'b', 'c', 'd'], dtype='object')\n",
    "\n",
    "    A Tensor can also be created from a pandas.DataFrame.\n",
    "\n",
    "    >>> x = pd.DataFrame(np.random.randint(0, 10, size=12).reshape((3, 4)),\n",
    "    ...                  index=list('xyz'),\n",
    "    ...                  columns=list('abcd'))\n",
    "    >>> x\n",
    "       a  b  c  d\n",
    "    x  6  1  8  9\n",
    "    y  1  5  2  1\n",
    "    z  5  9  4  5\n",
    "    >>> arr = Tensor(x)\n",
    "    >>> arr\n",
    "    Tensor([[6, 1, 8, 9],\n",
    "            [1, 5, 2, 1],\n",
    "            [5, 9, 4, 5]])\n",
    "    >>> arr.index\n",
    "    Index(['x', 'y', 'z'], dtype='object')\n",
    "    >>> arr.columns\n",
    "    Index(['a', 'b', 'c', 'd'], dtype='object')\n",
    "\n",
    "    It's possible to use any method of numpy.ndarray on the Tensor,\n",
    "    such as `sum`, `@`, etc.\n",
    "\n",
    "    >>> arr.sum(axis=0)\n",
    "    Tensor([15, 10, 12, 17])\n",
    "    >>> arr @ arr.T\n",
    "    Tensor([[ 74,  29,  40],\n",
    "            [ 29, 162, 134],\n",
    "            [ 40, 134, 116]])\n",
    "\n",
    "    If the Tensor is sliced, the values of `index` and `columns` will disappear,\n",
    "    and new values of type `RangeIndex` will be created.\n",
    "\n",
    "    >>> new_arr = arr[:, 1:3]\n",
    "    >>> new_arr\n",
    "    Tensor([[1, 8],\n",
    "            [5, 2],\n",
    "            [9, 4]])\n",
    "    >>> new_arr.index\n",
    "    RangeIndex(start=0, stop=3, step=1)\n",
    "    >>> new_arr.columns\n",
    "    RangeIndex(start=0, stop=2, step=1)\n",
    "\n",
    "    If you want to retain the values of `index` and `columns`,\n",
    "    you can reassign them.\n",
    "\n",
    "    >>> new_arr.index = arr.index[:]\n",
    "    >>> new_arr.index\n",
    "    Index(['x', 'y', 'z'], dtype='object')\n",
    "\n",
    "    >>> new_arr.columns = arr.columns[1:3]\n",
    "    >>> new_arr.columns\n",
    "    Index(['b', 'c'], dtype='object')\n",
    "\n",
    "    We recommend performing slicing operations in the following way\n",
    "    to keep the `index` and `columns` values.\n",
    "\n",
    "    >>> new_arr = Tensor(array=arr[:, 1:3],\n",
    "    ...                  index=arr.index[:, 1:3],\n",
    "    ...                  columns=arr.columns[:, 1:3])\n",
    "    >>> new_arr.index\n",
    "    Index(['x', 'y', 'z'], dtype='object')\n",
    "    >>> new_arr.columns\n",
    "    Index(['b', 'c'], dtype='object')\n",
    "    \"\"\"\n",
    "\n",
    "    def __new__(cls, object=None, index=None, columns=None):\n",
    "\n",
    "        if object is None:\n",
    "            raise TypeError(\"Tensor() missing required argument 'object' (pos 0)\")\n",
    "        elif isinstance(object, list):\n",
    "            object = np.array(object)\n",
    "        elif isinstance(object, pd.DataFrame):\n",
    "            index = object.index\n",
    "            columns = object.columns\n",
    "            object = object.values\n",
    "        elif isinstance(object, (np.ndarray, cls)):\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Type of the required argument 'object' must be array-like.\"\n",
    "            )\n",
    "        if index is None:\n",
    "            index = range(object.shape[0])\n",
    "        if columns is None:\n",
    "            columns = range(object.shape[1])\n",
    "        obj = np.asarray(object).view(cls)\n",
    "        obj.index = index\n",
    "        obj.columns = columns\n",
    "\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        if obj is None: return\n",
    "        if self.ndim == 0: return\n",
    "        elif self.ndim == 1:\n",
    "            self.columns = RangeIndex(0, 1, step=1, dtype=int)\n",
    "        else:\n",
    "            self.columns = RangeIndex(0, self.shape[1], step=1, dtype=int)\n",
    "        self.index = RangeIndex(0, self.shape[0], step=1, dtype=int)\n",
    "\n",
    "    @property\n",
    "    def index(self):\n",
    "        return self._index\n",
    "\n",
    "    @index.setter\n",
    "    def index(self, value):\n",
    "        assert isinstance(value, Iterable)\n",
    "        if len(list(value)) != self.shape[0]:\n",
    "            raise ValueError(\"Size of value is not equal to the shape[0].\")\n",
    "        self._index = Index(value)\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return self._columns\n",
    "\n",
    "    @columns.setter\n",
    "    def columns(self, value):\n",
    "        assert isinstance(value, Iterable)\n",
    "        if (self.ndim > 1 and len(list(value)) != self.shape[1]):\n",
    "            raise ValueError(\"Size of value is not equal to the shape[1].\")\n",
    "        self._columns = Index(value)\n",
    "\n",
    "\n",
    "class ALTrainer(object):\n",
    "\n",
    "    def __init__(self, n, d, model, lr, init_iter, alpha, beta, rho, rho_thresh,\n",
    "                 h_thresh, l1_penalty, gamma, early_stopping,\n",
    "                 early_stopping_thresh, seed, device=None):\n",
    "        self.n = n\n",
    "        self.d = d\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.init_iter = init_iter\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta  # rho_multiply\n",
    "        self.rho = rho\n",
    "        self.rho_thresh = rho_thresh\n",
    "        self.h_thresh = h_thresh  # 1e-8\n",
    "        self.l1_penalty = l1_penalty\n",
    "        self.gamma = gamma\n",
    "        self.early_stopping = early_stopping\n",
    "        self.early_stopping_thresh = early_stopping_thresh\n",
    "        self.seed = seed\n",
    "        self.device = device\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                          lr=self.lr)\n",
    "\n",
    "    def train(self, x, epochs, update_freq):\n",
    "\n",
    "        alpha, beta, rho = self.alpha, self.beta, self.rho\n",
    "        h, h_new = np.inf, np.inf\n",
    "        prev_w_est, prev_mse = None, np.inf\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            logging.info(f'Current epoch: {epoch}==================')\n",
    "            while rho < self.rho_thresh:\n",
    "                mse_new, h_new, w_new = self.train_step(x,\n",
    "                                                        update_freq,\n",
    "                                                        alpha,\n",
    "                                                        rho)\n",
    "                if h_new > self.gamma * h:\n",
    "                    rho *= self.beta\n",
    "                else:\n",
    "                    break\n",
    "            logging.info(f'Current        h: {h_new}')\n",
    "\n",
    "            if self.early_stopping:\n",
    "                if (mse_new / prev_mse > self.early_stopping_thresh\n",
    "                        and h_new <= 1e-7):\n",
    "                    return prev_w_est\n",
    "                else:\n",
    "                    prev_w_est = w_new\n",
    "                    prev_mse = mse_new\n",
    "\n",
    "            # update rules\n",
    "            w_est, h = w_new, h_new\n",
    "            alpha += rho * h_new.detach().cpu()\n",
    "\n",
    "            if h <= self.h_thresh and epoch > self.init_iter:\n",
    "                break\n",
    "\n",
    "        return w_est\n",
    "\n",
    "\n",
    "    def train_step(self, x, update_freq, alpha, rho):\n",
    "\n",
    "        curr_mse, curr_h, w_adj = None, None, None\n",
    "        for _ in range(update_freq):\n",
    "            torch.manual_seed(self.seed)\n",
    "            curr_mse, w_adj = self.model(x)\n",
    "            curr_h = compute_h(w_adj)\n",
    "            loss = ((0.5 / self.n) * curr_mse\n",
    "                    + self.l1_penalty * torch.norm(w_adj, p=1)\n",
    "                    + alpha * curr_h + 0.5 * rho * curr_h * curr_h)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if _ % LOG_FREQUENCY == 0:\n",
    "                logging.info(f'Current loss in step {_}: {loss.detach()}')\n",
    "\n",
    "        return curr_mse, curr_h, w_adj\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Feed-forward neural networks----MLP\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, layers, units, output_dim,\n",
    "                 activation=None, device=None) -> None:\n",
    "        super(MLP, self).__init__()\n",
    "        # self.desc = desc\n",
    "        self.input_dim = input_dim\n",
    "        self.layers = layers\n",
    "        self.units = units\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        self.device = device\n",
    "\n",
    "        mlp = []\n",
    "        for i in range(layers):\n",
    "            input_size = units\n",
    "            if i == 0:\n",
    "                input_size = input_dim\n",
    "            weight = nn.Linear(in_features=input_size,\n",
    "                               out_features=self.units,\n",
    "                               bias=True,\n",
    "                               device=self.device)\n",
    "            mlp.append(weight)\n",
    "            if activation is not None:\n",
    "                mlp.append(activation)\n",
    "        out_layer = nn.Linear(in_features=self.units,\n",
    "                              out_features=self.output_dim,\n",
    "                              bias=True,\n",
    "                              device=self.device)\n",
    "        mlp.append(out_layer)\n",
    "\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "\n",
    "        x_ = x.reshape(-1, self.input_dim)\n",
    "        output = self.mlp(x_)\n",
    "\n",
    "        return output.reshape(x.shape[0], -1, self.output_dim)\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d, input_dim, hidden_layers=3, hidden_dim=16,\n",
    "                 activation=nn.ReLU(), device=None):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.d = d\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation = activation\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = MLP(input_dim=self.input_dim,\n",
    "                           layers=self.hidden_layers,\n",
    "                           units=self.hidden_dim,\n",
    "                           output_dim=self.hidden_dim,\n",
    "                           activation=self.activation,\n",
    "                           device=self.device)\n",
    "        self.decoder = MLP(input_dim=self.hidden_dim,\n",
    "                           layers=self.hidden_layers,\n",
    "                           units=self.hidden_dim,\n",
    "                           output_dim=self.input_dim,\n",
    "                           activation=self.activation,\n",
    "                           device=self.device)\n",
    "\n",
    "        w = torch.nn.init.uniform_(torch.empty(self.d, self.d,),\n",
    "                                   a=-0.1, b=0.1)\n",
    "        self.w = torch.nn.Parameter(w.to(device=self.device))\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        self.w_adj = self._preprocess_graph(self.w)\n",
    "\n",
    "        out = self.encoder(x)\n",
    "        out = torch.einsum('ijk,jl->ilk', out, self.w_adj)\n",
    "        # x_est = self.decoder(out)\n",
    "        x_est = torch.sigmoid(self.decoder(out))\n",
    "\n",
    "        # mse_loss = torch.square(torch.norm(x - x_est, p=2))\n",
    "        mse_loss = F.binary_cross_entropy(x, x_est)\n",
    "\n",
    "\n",
    "        return mse_loss, self.w_adj\n",
    "\n",
    "    def _preprocess_graph(self, w_adj):\n",
    "\n",
    "        return (1. - torch.eye(w_adj.shape[0], device=self.device)) * w_adj\n",
    "\n",
    "\n",
    "class GAE:\n",
    "    \"\"\"\n",
    "    GAE Algorithm.\n",
    "    A gradient-based algorithm using graph autoencoder to model non-linear\n",
    "    causal relationships.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_dim: int, default: 1\n",
    "        dimension of vector for x\n",
    "    hidden_layers: int, default: 1\n",
    "        number of hidden layers for encoder and decoder\n",
    "    hidden_dim: int, default: 4\n",
    "        hidden size for mlp layer\n",
    "    activation: callable, default: nn.LeakyReLU(0.05)\n",
    "        nonlinear functional\n",
    "    epochs: int, default: 10\n",
    "        Number of iterations for optimization problem\n",
    "    update_freq: int, default: 3000\n",
    "        Number of steps for each iteration\n",
    "    init_iter: int, default: 3\n",
    "        Initial iteration to disallow early stopping\n",
    "    lr: float, default: 1e-3\n",
    "        learning rate\n",
    "    alpha: float, default: 0.0\n",
    "        Lagrange multiplier\n",
    "    beta: float, default: 2.0\n",
    "        Multiplication to amplify rho each time\n",
    "    init_rho: float, default: 1.0\n",
    "        Initial value for rho\n",
    "    rho_thresh: float, default: 1e30\n",
    "        Threshold for rho\n",
    "    gamma: float, default: 0.25\n",
    "        Threshold for h\n",
    "    penalty_lambda: float, default: 0.0\n",
    "        L1 penalty for sparse graph. Set to 0.0 to disable\n",
    "    h_thresh: float, default: 1e-8\n",
    "        Tolerance of optimization problem\n",
    "    graph_thresh: float, default: 0.3\n",
    "        Threshold to filter out small values in graph\n",
    "    early_stopping: bool, default: False\n",
    "        Whether to use early stopping\n",
    "    early_stopping_thresh: float, default: 1.0\n",
    "        Threshold ratio for early stopping\n",
    "    seed: int, default: 1230\n",
    "        Reproducibility, must be int\n",
    "    device_type: str, default: 'cpu'\n",
    "        'cpu' or 'gpu'\n",
    "    device_ids: int or str, default '0'\n",
    "        CUDA devices, it's effective when ``use_gpu`` is True.\n",
    "        For single-device modules, ``device_ids`` can be int or str,\n",
    "        e.g. 0 or '0', For multi-device modules, ``device_ids`` must be str,\n",
    "        format like '0, 1'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim=1,\n",
    "                 hidden_layers=1,\n",
    "                 hidden_dim=4,\n",
    "                 activation=torch.nn.LeakyReLU(0.05),\n",
    "                 epochs=10,\n",
    "                 update_freq=3000,\n",
    "                 init_iter=3,\n",
    "                 lr=1e-3,\n",
    "                 alpha=0.0,\n",
    "                 beta=2.0,\n",
    "                 init_rho=1.0,\n",
    "                 rho_thresh=1e30,\n",
    "                 gamma=0.25,\n",
    "                 penalty_lambda=0.0,\n",
    "                 h_thresh=1e-8,\n",
    "                 graph_thresh=0.3,\n",
    "                 early_stopping=False,\n",
    "                 early_stopping_thresh=1.0,\n",
    "                 seed=1230,\n",
    "                 device_type='cpu',\n",
    "                 device_ids='0'):\n",
    "\n",
    "        super(GAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.activation = activation\n",
    "        self.epochs = epochs\n",
    "        self.update_freq = update_freq\n",
    "        self.init_iter = init_iter\n",
    "        self.lr = lr\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.init_rho = init_rho\n",
    "        self.rho_thresh = rho_thresh\n",
    "        self.gamma = gamma\n",
    "        self.penalty_lambda = penalty_lambda\n",
    "        self.h_thresh = h_thresh\n",
    "        self.graph_thresh = graph_thresh\n",
    "        self.early_stopping = early_stopping\n",
    "        self.early_stopping_thresh = early_stopping_thresh\n",
    "        self.seed = seed\n",
    "        self.device_type = device_type\n",
    "        self.device_ids = device_ids\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            logging.info('GPU is available.')\n",
    "        else:\n",
    "            logging.info('GPU is unavailable.')\n",
    "            if self.device_type == 'gpu':\n",
    "                raise ValueError(\"GPU is unavailable, \"\n",
    "                                 \"please set device_type = 'cpu'.\")\n",
    "        if self.device_type == 'gpu':\n",
    "            if self.device_ids:\n",
    "                os.environ['CUDA_VISIBLE_DEVICES'] = str(self.device_ids)\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        self.device = device\n",
    "\n",
    "    def learn(self, data, columns=None, **kwargs):\n",
    "\n",
    "        x = torch.from_numpy(data)\n",
    "\n",
    "        self.n, self.d = x.shape[:2]\n",
    "        if x.ndim == 2:\n",
    "            x = x.reshape((self.n, self.d, 1))\n",
    "            self.input_dim = 1\n",
    "        elif x.ndim == 3:\n",
    "            self.input_dim = x.shape[2]\n",
    "\n",
    "        w_est = self._gae(x).detach().cpu().numpy()\n",
    "\n",
    "        self.weight_causal_matrix = Tensor(w_est,\n",
    "                                           index=columns,\n",
    "                                           columns=columns)\n",
    "        causal_matrix = (abs(w_est) > self.graph_thresh).astype(int)\n",
    "        self.causal_matrix = Tensor(causal_matrix,\n",
    "                                    index=columns,\n",
    "                                    columns=columns)\n",
    "\n",
    "    def _gae(self, x):\n",
    "\n",
    "        set_seed(self.seed)\n",
    "        model = AutoEncoder(d=self.d,\n",
    "                            input_dim=self.input_dim,\n",
    "                            hidden_layers=self.hidden_layers,\n",
    "                            hidden_dim=self.hidden_dim,\n",
    "                            activation=self.activation,\n",
    "                            device=self.device,\n",
    "                            )\n",
    "        trainer = ALTrainer(n=self.n,\n",
    "                            d=self.d,\n",
    "                            model=model,\n",
    "                            lr=self.lr,\n",
    "                            init_iter=self.init_iter,\n",
    "                            alpha=self.alpha,\n",
    "                            beta=self.beta,\n",
    "                            rho=self.init_rho,\n",
    "                            l1_penalty=self.penalty_lambda,\n",
    "                            rho_thresh=self.rho_thresh,\n",
    "                            h_thresh=self.h_thresh,  # 1e-8\n",
    "                            early_stopping=self.early_stopping,\n",
    "                            early_stopping_thresh=self.early_stopping_thresh,\n",
    "                            gamma=self.gamma,\n",
    "                            seed=self.seed,\n",
    "                            device=self.device)\n",
    "        w_est = trainer.train(x=x,\n",
    "                              epochs=self.epochs,\n",
    "                              update_freq=self.update_freq)\n",
    "        w_est = w_est / torch.max(abs(w_est))\n",
    "\n",
    "        return w_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'testing_results.csv' already exists.\n"
     ]
    }
   ],
   "source": [
    "#  set up testing collection df\n",
    "\n",
    "testing_results_columns = ['date', 'dataset', 'subset', 'n', 'method', 'runtime', 'hyperparams',\n",
    "                                        'fdr', 'tpr', 'fpr', 'shd', 'nnz', 'precision', 'recall', 'F1', 'gscore']\n",
    "\n",
    "# Check if the file exists\n",
    "try:\n",
    "    with open('testing_results.csv', 'r') as csvfile:\n",
    "        print(\"File 'testing_results.csv' already exists.\")\n",
    "except FileNotFoundError:\n",
    "    # Create a new file with the specified columns\n",
    "    with open('testing_results.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(testing_results_columns)\n",
    "        print(\"New file 'testing_results.csv' created with the specified columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Function to save the date to the testing_results.csv\n",
    "\n",
    "def add_results(dataset, subset, n, method, runtime, hyperparams, metrics):\n",
    "    with open('testing_results.csv', 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "\n",
    "        if metrics != None:\n",
    "            writer.writerow([time.strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
    "                            dataset, \n",
    "                            subset,\n",
    "                            n, \n",
    "                            method, \n",
    "                            runtime, \n",
    "                            hyperparams,\n",
    "                            metrics['fdr'],\n",
    "                            metrics['tpr'],\n",
    "                            metrics['fpr'],\n",
    "                            metrics['shd'],\n",
    "                            metrics['nnz'],\n",
    "                            metrics['precision'],\n",
    "                            metrics['recall'],\n",
    "                            metrics['F1'],\n",
    "                            metrics['gscore']]\n",
    "                            )\n",
    "        else:\n",
    "            writer.writerow([time.strftime(\"%Y-%m-%d %H:%M:%S\"), \n",
    "                            dataset, \n",
    "                            subset,\n",
    "                            n, \n",
    "                            method, \n",
    "                            runtime, \n",
    "                            hyperparams,\n",
    "                            ]\n",
    "                            )\n",
    "        print(\"Results added to 'testing_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and save a graph plot next to a heatmap\n",
    "\n",
    "def plot_graph_adjacency_matrix(ground_truth, save_name):\n",
    "\n",
    "    # create figure\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(15, 8), ncols=2)\n",
    "\n",
    "    # subplot for graph\n",
    "    ax1.set_title('Graph', y= 1.05)\n",
    "    G = nx.from_numpy_matrix(ground_truth, create_using=nx.DiGraph)\n",
    "    nx.draw(G, ax=ax1, with_labels=True)\n",
    "\n",
    "    # subplot for heatmap\n",
    "    ax2.set_title('Adjazenzmatrix Heat Map', y= 1.05)\n",
    "    map1 = ax2.imshow(ground_truth, cmap='Greys', interpolation='none')\n",
    "    cbar = fig.colorbar(map1, ax=ax2)\n",
    "    cbar.ax.set_position([cbar.ax.get_position().x0, ax2.get_position().y0,\n",
    "                        cbar.ax.get_position().width, ax2.get_position().height])\n",
    "\n",
    "    # Ensure subplots have same height and position in y direction\n",
    "    ax1_height = ax2.get_position().height\n",
    "    ax1.set_position([ax1.get_position().x0, ax2.get_position().y0,\n",
    "                    ax1.get_position().width, ax1_height])\n",
    "    ax2.set_position([ax2.get_position().x0, ax2.get_position().y0,\n",
    "                    ax2.get_position().width, ax1_height])\n",
    "\n",
    "    # save\n",
    "    plt.savefig(save_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to only save a heat map\n",
    "\n",
    "def plot_heatmap(ground_truth, method, save_name):\n",
    "    \n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # subplot for heatmap\n",
    "    ax.set_title(method, y= 1.05)\n",
    "    map1 = ax.imshow(ground_truth, cmap='Greys', interpolation='none')\n",
    "    cbar = fig.colorbar(map1, ax=ax)\n",
    "    cbar.ax.set_position([cbar.ax.get_position().x0, ax.get_position().y0,\n",
    "                        cbar.ax.get_position().width, ax.get_position().height])\n",
    "\n",
    "    # save\n",
    "    plt.savefig(save_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test setup\n",
    "\n",
    "def run_tests(dataset, subset, algorithms, sample_sizes, ground_truth_available:bool):\n",
    "    \n",
    "    if ground_truth_available:\n",
    "        ground_truth = pd.read_csv(f'data/{dataset}/{subset}/{subset}_ground_truth.csv').to_numpy()\n",
    "\n",
    "    algorithms_gcastle = ['NotearsLinear', 'GAE', 'DirectLiNGAM', 'PC']\t\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "\n",
    "        data = pd.read_csv(f'data/{dataset}/{subset}/{subset}_data_{sample_size}.csv').to_numpy()\n",
    "\n",
    "        # go over all algorithms\n",
    "        for algorithm in algorithms:\n",
    "\n",
    "            # set different params for the different models\n",
    "            match algorithm:\n",
    "\n",
    "                case 'NotearsLinear':\n",
    "                    model = Notears(loss_type='logistic')\n",
    "                    start_time = time.time()\n",
    "                    model.learn(data)\n",
    "                    end_time = time.time()             \n",
    "\n",
    "                case 'DagmaLinear':\n",
    "                    model = DagmaLinear(loss_type='logistic')\n",
    "                    start_time = time.time()\n",
    "                    W_est = (model.fit(data, max_iter=1e6) > 0.5).astype(\"int32\")\n",
    "                    end_time = time.time()\n",
    "\n",
    "                case 'GAE':\n",
    "                    model = GAE(epochs=3)\n",
    "                    start_time = time.time()\n",
    "                    model.learn(data)\n",
    "                    end_time = time.time()\n",
    "\n",
    "                case 'DirectLiNGAM':\n",
    "                    model = DirectLiNGAM()\n",
    "                    start_time = time.time()\n",
    "                    model.learn(data)\n",
    "                    end_time = time.time()\n",
    "\n",
    "                case 'PC':\n",
    "                    model = PC(variant = 'stable')\n",
    "                    start_time = time.time()\n",
    "                    model.learn(data)\n",
    "                    end_time = time.time()\n",
    "\n",
    "\n",
    "            # calculate runtime\n",
    "            runtime = end_time - start_time\n",
    "\n",
    "            # plot comparison graph\n",
    "            name = f'{algorithm}_{sample_size}'\n",
    "            print(name)\n",
    "            save_name1 = f'plots/adj_matrix_comparison/{dataset}/{subset}/{name}.png'\n",
    "\n",
    "            # plot only heatmap for later comparison\n",
    "            save_name2 = f'plots/adj_matrix/{dataset}/{subset}/{name}.png'\n",
    "\n",
    "            # save adj_matrix as csv\n",
    "            save_name3 = f'plots/adj_matrix_csv/{dataset}/{subset}/{name}.csv'\n",
    "\n",
    "            match algorithm:\n",
    "\n",
    "                case algorithm if algorithm in algorithms_gcastle:\n",
    "                    if ground_truth_available:\n",
    "                        met = MetricsDAG(model.causal_matrix, ground_truth).metrics\n",
    "                        GraphDAG(model.causal_matrix, ground_truth, save_name = save_name1)\n",
    "                    elif not ground_truth_available:\n",
    "                        met = None\n",
    "                    plot_heatmap(model.causal_matrix, method = algorithm, save_name = save_name2)\n",
    "                    df = pd.DataFrame(np.array(model.causal_matrix.tolist()).reshape(model.causal_matrix.shape))\n",
    "\n",
    "                case 'DagmaLinear':\n",
    "                    if ground_truth_available:\n",
    "                        met = MetricsDAG(W_est, ground_truth).metrics\n",
    "                        GraphDAG(W_est, ground_truth, save_name = save_name1)\n",
    "                    elif not ground_truth_available:\n",
    "                        met = None\n",
    "                    plot_heatmap(W_est, method = algorithm, save_name = save_name2)\n",
    "                    df = pd.DataFrame(np.array(W_est.tolist()).reshape(W_est.shape))\n",
    "\n",
    "                # case 'NotearsLinear':\n",
    "                #     met = MetricsDAG(model.causal_matrix, ground_truth)\n",
    "                #     GraphDAG(model.causal_matrix, ground_truth, save_name = save_name1)\n",
    "                #     plot_heatmap(model.causal_matrix, method = algorithm, save_name = save_name2)\n",
    "                #     df = pd.DataFrame(np.array(model.causal_matrix.tolist()).reshape(model.causal_matrix.shape))\n",
    "                # case 'DagmaLinear':\n",
    "                #     met = MetricsDAG(W_est, ground_truth)\n",
    "                #     GraphDAG(W_est, ground_truth, save_name = save_name1)\n",
    "                #     plot_heatmap(W_est, method = algorithm, save_name = save_name2)\n",
    "                #     df = pd.DataFrame(np.array(W_est.tolist()).reshape(W_est.shape))\n",
    "                # case 'GAE':\n",
    "                #     met = MetricsDAG(model.causal_matrix, ground_truth)\n",
    "                #     GraphDAG(model.causal_matrix, ground_truth, save_name = save_name1)\n",
    "                #     plot_heatmap(model.causal_matrix, method = algorithm, save_name = save_name2)\n",
    "                #     df = pd.DataFrame(np.array(model.causal_matrix.tolist()).reshape(model.causal_matrix.shape))\n",
    "                # case 'DirectLiNGAM':\n",
    "                #     met = MetricsDAG(model.causal_matrix, ground_truth)\n",
    "                #     GraphDAG(model.causal_matrix, ground_truth, save_name = save_name1)\n",
    "                #     plot_heatmap(model.causal_matrix, method = algorithm, save_name = save_name2)\n",
    "                #     df = pd.DataFrame(np.array(model.causal_matrix.tolist()).reshape(model.causal_matrix.shape))\n",
    "                # case 'PC':\n",
    "                #     met = MetricsDAG(model.causal_matrix, ground_truth)\n",
    "                #     GraphDAG(model.causal_matrix, ground_truth, save_name = save_name1)\n",
    "                #     plot_heatmap(model.causal_matrix, method = algorithm, save_name = save_name2)\n",
    "                #     df = pd.DataFrame(np.array(model.causal_matrix.tolist()).reshape(model.causal_matrix.shape))\n",
    "\n",
    "            # save adj matrix to csv\n",
    "            df.to_csv(save_name3, index=False)\n",
    "\n",
    "            # save metrics to csv\n",
    "            add_results(dataset, subset, sample_size, algorithm, runtime, None, met) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define testing parameters\n",
    "\n",
    "algorithms = [\n",
    "              # 'NotearsLinear'\n",
    "              # , 'DagmaLinear'\n",
    "              # 'GAE'\n",
    "            #   , 'DirectLiNGAM'\n",
    "              'PC'\n",
    "              ]\n",
    "\n",
    "sample_sizes = [500]\n",
    "\n",
    "datasets = ['IID']\n",
    "subsets = ['IID3']\n",
    "\n",
    "# change between experiments where the ground truth is known and those where it is not\n",
    "ground_truth_available = False\n",
    "\n",
    "runs = range(0,1)\n",
    "\n",
    "# from castle.algorithms import GAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'IID3_data_500.csv' exists.\n",
      "PC_500\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results added to 'testing_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    for dataset in datasets:\n",
    "        for subset in subsets:\n",
    "            # check if a file exists in the data folder and if yes, do run_tests\n",
    "            try:\n",
    "                with open(f'data/{dataset}/{subset}/{subset}_data_{sample_sizes[0]}.csv', 'r') as csvfile:\n",
    "                    print(f\"File '{subset}_data_{sample_sizes[0]}.csv' exists.\")\n",
    "                    run_tests(dataset, subset, algorithms, sample_sizes, ground_truth_available)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"The combination of {dataset} and {subset} does not exist.\")\n",
    "                pass\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
